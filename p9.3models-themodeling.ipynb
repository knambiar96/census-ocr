{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58072f4f-a1ce-4a4d-8bef-7796d0807e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def5c244-9b8f-4441-9558-6267ab30a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Reshape, Dense, Bidirectional, Dropout, LSTM \n",
    ",StringLookup, ConvLSTM2D)\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.backend import ctc_decode, ctc_batch_cost\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "import Levenshtein as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda43202-dd04-411b-9547-a9b2401bcaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21e280-5f81-475a-a311-8140ccb6c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./labeltensor_shpad.pkl','rb') as ry:\n",
    "    lab_tensor_sh = pickle.load(ry)\n",
    "\n",
    "with open('./drive/MyDrive/imgtensor_trsh.pkl','rb') as arbi:\n",
    "    img_tensor_trsh = pickle.load(arbi)\n",
    "\n",
    "charlist = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz .,-+1234567890'\n",
    "\n",
    "def CTCLoss(y_true, y_pred):\n",
    "    # Compute the training-time loss value\n",
    "    #trying this method here-  \n",
    "    #https://stackoverflow.com/questions/64321779/how-to-use-tf-ctc-loss-with-variable-length-features-and-labels\n",
    "    label_length = tf.math.count_nonzero(y_true, axis= -1, keepdims = True)\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def decode_preds(pred_model,start,end):\n",
    "    preds = pred_model.predict(img_tensor_trsh[start:end])\n",
    "    len_tensor = tf.convert_to_tensor([len([l for l in lab if l>0]) for lab in lab_tensor_sh[start:end]])\n",
    "    pred_texts = ctc_decode(preds,len_tensor,greedy=True)\n",
    "    guess_list =  [''.join([charlist[p-1] for p in pred.numpy() if p > -1]) for pred in pred_texts[0][0]]\n",
    "    prob_list = pred_texts[1].numpy()\n",
    "    return guess_list,prob_list\n",
    "\n",
    "def post_distance(pred_model,start,end):\n",
    "    preds, _ = decode_preds(pred_model,start,end)\n",
    "    trues = [''.join([charlist[p-1] for p in lab.numpy() if p>0]) for lab in lab_tensor_sh[start:end]]\n",
    "    return np.mean([lev.distance(trues[i],preds[i]) for i in range(end-start)])\n",
    "# you can normalize the lev distance by dividing by length of longest word, but we'll leave that for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4fe967-3b0e-404a-8d40-5db60c0f772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(679,480,1),name='image',dtype=\"float32\")\n",
    "\n",
    "\n",
    "x = Conv2D(32,(3,3),activation='relu',name='Conv1')(input_img)\n",
    "x = MaxPooling2D((2,2), name = \"pool1\")(x)\n",
    "x = Dropout(0.3,name = 'drop1')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(64,(3,3),activation='relu',name='Conv2')(x)\n",
    "x = MaxPooling2D((2,2), name = \"pool2\")(x)\n",
    "x = Dropout(0.3, name = 'drop2')(x)\n",
    "\n",
    "x = Conv2D(128,(4,4), activation= 'relu',name='Conv3')(x)\n",
    "x = Conv2D(128,(5,5),activation='relu', name = 'Conv4')(x)\n",
    "x = MaxPooling2D((2,2), name = 'pool3')(x)\n",
    "x = Dropout(0.3,name = 'drop3')(x)\n",
    "\n",
    "x = Conv2D(128,(5,5), activation= 'relu', name = 'Conv5')(x)\n",
    "\n",
    "shape = (152,3264)\n",
    "\n",
    "x = Reshape(target_shape=shape, name = 'reshape')(x)\n",
    "x = Dense(64, activation='relu', name ='dense1')(x)\n",
    "x = Dropout(0.2,name = 'drop4')(x)\n",
    "\n",
    "x = Bidirectional(LSTM(256,return_sequences=True, dropout=0.25), name = 'LSTM1')(x)\n",
    "x = Bidirectional(LSTM(128,return_sequences=True,dropout=0.25), name = 'LSTM2')(x)\n",
    "x = Bidirectional(LSTM(64,return_sequences=True,dropout=0.25), name = 'LSTM3')(x)\n",
    "x = Bidirectional(LSTM(32,return_sequences=True,dropout=0.25), name = 'LSTM4')(x)\n",
    "\n",
    "\n",
    "output = Dense(len(charlist)+1,activation='softmax',name='dense2')(x)\n",
    "\n",
    "\n",
    "model = Model(input_img,output,name='basic-OCRplusvartr')\n",
    "model.compile(optimizer='adam',loss=CTCLoss) #try different optimizers, lstm rows, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d16ef6-3b88-437e-839c-85ed57951494",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 100\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    ")\n",
    "history = model2.fit(img_tensor_trsh,lab_tensor_sh,validation_split=0.2, epochs=eps,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2353432-9d57-412f-abd4-cc7d525c7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = Model(model.get_layer(name=\"image\").input, model.get_layer(name='dense2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc29be-2bb3-4e4d-938f-63afba3f52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses, probs = decode_preds(prediction_model,0,1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71e53e-5b41-4f51-ac0d-2ff6cc3accb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_distance(prediction_model,0,1407)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
